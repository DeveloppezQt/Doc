<?xml version="1.0" encoding="UTF-8"?>
<db:article xmlns:db="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.2" xml:lang="en">
<db:info>
<db:title>Qt Test Overview</db:title>
<db:productname>QtTestLib</db:productname>
<db:edition>Qt 6.3.2 Reference Documentation</db:edition>
<db:titleabbrev>Qt Test Reference Documentation</db:titleabbrev>
<db:abstract>
<db:para>Overview of the Qt unit testing framework.</db:para>
</db:abstract>
<db:pubdate>2024-12-27</db:pubdate>
<db:date>2024-12-27</db:date>
<db:authorgroup>
<db:author>
<db:orgname class="corporation">The Qt Company Ltd.</db:orgname>
</db:author>
</db:authorgroup>
</db:info>
<db:para>Qt Test is a framework for unit testing Qt based applications and libraries. Qt Test provides all the functionality commonly found in unit testing frameworks as well as extensions for testing graphical user interfaces.</db:para>
<db:para>Qt Test is designed to ease the writing of unit tests for Qt based applications and libraries:</db:para>
<db:informaltable style="generic">
<db:thead>
<db:tr>
<db:th>
<db:para>Feature</db:para>
</db:th>
<db:th>
<db:para>Details</db:para>
</db:th>
</db:tr>
</db:thead>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Lightweight</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Qt Test consists of about 6000 lines of code and 60 exported symbols.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Self-contained</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Qt Test requires only a few symbols from the Qt Core module for non-gui testing.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Rapid testing</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Qt Test needs no special test-runners; no special registration for tests.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Data-driven testing</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>A test can be executed multiple times with different test data.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Basic GUI testing</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Qt Test offers functionality for mouse and keyboard simulation.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Benchmarking</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Qt Test supports benchmarking and provides several measurement back-ends.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">IDE friendly</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Qt Test outputs messages that can be interpreted by Qt Creator, Visual Studio, and KDevelop.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Thread-safety</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>The error reporting is thread safe and atomic.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Type-safety</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Extensive use of templates prevent errors introduced by implicit type casting.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para><db:emphasis role="bold">Easily extendable</db:emphasis></db:para>
</db:td>
<db:td>
<db:para>Custom types can easily be added to the test data and test output.</db:para>
</db:td>
</db:tr>
</db:informaltable>
<db:para>You can use a Qt Creator wizard to create a project that contains Qt tests and build and run them directly from Qt Creator. For more information, see <db:link xlink:href="https://doc.qt.io/qtcreator/creator-autotest.html">Running Autotests</db:link>.</db:para>
<db:section xml:id="creating-a-test">
<db:title>Creating a Test</db:title>
<db:para>To create a test, subclass <db:link xlink:href="qobject.xml">QObject</db:link> and add one or more private slots to it. Each private slot is a test function in your test. <db:link xlink:href="qtest.xml#qExec">QTest::qExec</db:link>() can be used to execute all test functions in the test object.</db:para>
<db:para>In addition, you can define the following private slots that are <db:emphasis>not</db:emphasis> treated as test functions. When present, they will be executed by the testing framework and can be used to initialize and clean up either the entire test or the current test function.</db:para>
<db:itemizedlist>
<db:listitem>
<db:para><db:code>initTestCase()</db:code> will be called before the first test function is executed.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>initTestCase_data()</db:code> will be called to create a global test data table.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>cleanupTestCase()</db:code> will be called after the last test function was executed.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>init()</db:code> will be called before each test function is executed.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>cleanup()</db:code> will be called after every test function.</db:para>
</db:listitem>
</db:itemizedlist>
<db:para>Use <db:code>initTestCase()</db:code> for preparing the test. Every test should leave the system in a usable state, so it can be run repeatedly. Cleanup operations should be handled in <db:code>cleanupTestCase()</db:code>, so they get run even if the test fails.</db:para>
<db:para>Use <db:code>init()</db:code> for preparing a test function. Every test function should leave the system in a usable state, so it can be run repeatedly. Cleanup operations should be handled in <db:code>cleanup()</db:code>, so they get run even if the test function fails and exits early.</db:para>
<db:para>Alternatively, you can use RAII (resource acquisition is initialization), with cleanup operations called in destructors, to ensure they happen when the test function returns and the object moves out of scope.</db:para>
<db:para>If <db:code>initTestCase()</db:code> fails, no test function will be executed. If <db:code>init()</db:code> fails, the following test function will not be executed, the test will proceed to the next test function.</db:para>
<db:para>Example:</db:para>
<db:programlisting language="cpp">class MyFirstTest: public QObject
{
    Q_OBJECT

private:
    bool myCondition()
    {
        return true;
    }

private slots:
    void initTestCase()
    {
        qDebug(&quot;Called before everything else.&quot;);
    }

    void myFirstTest()
    {
        QVERIFY(true); // check that a condition is satisfied
        QCOMPARE(1, 1); // compare two values
    }

    void mySecondTest()
    {
        QVERIFY(myCondition());
        QVERIFY(1 != 2);
    }

    void cleanupTestCase()
    {
        qDebug(&quot;Called after myFirstTest and mySecondTest.&quot;);
    }
};
</db:programlisting>
<db:para>Finally, if the test class has a static public <db:code>void initMain()</db:code> method, it is called by the <db:link xlink:href="qtest.xml#QTEST_MAIN">QTEST_MAIN</db:link> macros before the QApplication object is instantiated. This was added in 5.14.</db:para>
<db:para>For more examples, refer to the <db:link xlink:href="qtest-tutorial.xml">Qt Test Tutorial</db:link>.</db:para>
</db:section>
<db:section xml:id="building-a-test">
<db:title>Building a Test</db:title>
<db:para>You can build an executable that contains one test class that typically tests one class of production code. However, usually you would want to test several classes in a project by running one command.</db:para>
<db:para>See <db:link xlink:href="qttestlib-tutorial1-example.xml">Writing a Unit Test</db:link> for a step by step explanation.</db:para>
<db:section xml:id="building-with-cmake-and-ctest">
<db:title>Building with CMake and CTest</db:title>
<db:para>You can use <db:link xlink:href="qtest-overview.xml#building-with-cmake-and-ctest">Building with CMake and CTest</db:link> to create a test. <db:link xlink:href="https://cmake.org/cmake/help/latest/manual/ctest.1.html">CTest</db:link> enables you to include or exclude tests based on a regular expression that is matched against the test name. You can further apply the <db:code>LABELS</db:code> property to a test and CTest can then include or exclude tests based on those labels. All labeled targets will be run when <db:code>test</db:code> target is called on the command line.</db:para>
<db:note>
<db:para>On Android, if you have one connected device or emulator, tests will run on that device. If you have more than one device connected, set the environment variable <db:code>ANDROID_DEVICE_SERIAL</db:code> to the <db:link xlink:href="https://developer.android.com/studio/command-line/adb#devicestatus">ADB serial number</db:link> of the device that you want to run tests on.</db:para>
</db:note>
<db:para>There are several other advantages with CMake. For example, the result of a test run can be published on a web server using CDash with virtually no effort.</db:para>
<db:para>CTest scales to very different unit test frameworks, and works out of the box with <db:link xlink:href="qtest.xml">QTest</db:link>.</db:para>
<db:para>The following is an example of a CMakeLists.txt file that specifies the project name and the language used (here, <db:emphasis>mytest</db:emphasis> and C++), the Qt modules required for building the test (Qt5Test), and the files that are included in the test (<db:emphasis>tst_mytest.cpp</db:emphasis>).</db:para>
<db:programlisting language="cpp">project(mytest LANGUAGES CXX)

find_package(Qt6 REQUIRED COMPONENTS Test)

set(CMAKE_INCLUDE_CURRENT_DIR ON)

set(CMAKE_AUTOMOC ON)

enable_testing(true)

add_executable(mytest tst_mytest.cpp)
add_test(NAME mytest COMMAND mytest)

target_link_libraries(mytest PRIVATE Qt::Test)
</db:programlisting>
<db:para>For more information about the options you have, see <db:link xlink:href="">Build with CMake</db:link>.</db:para>
</db:section>
<db:section xml:id="building-with-qmake">
<db:title>Building with qmake</db:title>
<db:para>If you are using <db:code>qmake</db:code> as your build tool, just add the following to your project file:</db:para>
<db:programlisting language="cpp">QT += testlib
</db:programlisting>
<db:para>If you would like to run the test via <db:code>make check</db:code>, add the additional line:</db:para>
<db:programlisting language="cpp">CONFIG += testcase
</db:programlisting>
<db:para>To prevent the test from being installed to your target, add the additional line:</db:para>
<db:programlisting language="cpp">CONFIG += no_testcase_installs
</db:programlisting>
<db:para>See the <db:link xlink:href="">qmake manual</db:link> for more information about <db:code>make check</db:code>.</db:para>
</db:section>
<db:section xml:id="building-with-other-tools">
<db:title>Building with Other Tools</db:title>
<db:para>If you are using other build tools, make sure that you add the location of the Qt Test header files to your include path (usually <db:code>include/QtTest</db:code> under your Qt installation directory). If you are using a release build of Qt, link your test to the <db:code>QtTest</db:code> library. For debug builds, use <db:code>QtTest_debug</db:code>.</db:para>
</db:section>
</db:section>
<db:section xml:id="qt-test-command-line-arguments">
<db:title>Qt Test Command Line Arguments</db:title>
<db:section xml:id="syntax">
<db:title>Syntax</db:title>
<db:para>The syntax to execute an autotest takes the following simple form:</db:para>
<db:programlisting language="cpp">testname [options] [testfunctions[:testdata]]...
</db:programlisting>
<db:para>Substitute <db:code>testname</db:code> with the name of your executable. <db:code>testfunctions</db:code> can contain names of test functions to be executed. If no <db:code>testfunctions</db:code> are passed, all tests are run. If you append the name of an entry in <db:code>testdata</db:code>, the test function will be run only with that test data.</db:para>
<db:para>For example:</db:para>
<db:programlisting language="cpp">/myTestDirectory$ testQString toUpper
</db:programlisting>
<db:para>Runs the test function called <db:code>toUpper</db:code> with all available test data.</db:para>
<db:programlisting language="cpp">/myTestDirectory$ testQString toUpper toInt:zero
</db:programlisting>
<db:para>Runs the <db:code>toUpper</db:code> test function with all available test data, and the <db:code>toInt</db:code> test function with the test data row called <db:code>zero</db:code> (if the specified test data doesn't exist, the associated test will fail and the available data tags are reported).</db:para>
<db:programlisting language="cpp">/myTestDirectory$ testMyWidget -vs -eventdelay 500
</db:programlisting>
<db:para>Runs the <db:code>testMyWidget</db:code> function test, outputs every signal emission and waits 500 milliseconds after each simulated mouse/keyboard event.</db:para>
</db:section>
<db:section xml:id="options">
<db:title>Options</db:title>
<db:section xml:id="logging-options">
<db:title>Logging Options</db:title>
<db:para>The following command line options determine how test results are reported:</db:para>
<db:itemizedlist>
<db:listitem>
<db:para><db:code>-o</db:code> <db:emphasis>filename,format</db:emphasis>  Writes output to the specified file, in the specified format (one of <db:code>txt</db:code>, <db:code>xml</db:code>, <db:code>lightxml</db:code>, <db:code>junitxml</db:code> or <db:code>tap</db:code>). The special filename <db:code>-</db:code> may be used to log to standard output.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-o</db:code> <db:emphasis>filename</db:emphasis>  Writes output to the specified file.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-txt</db:code>  Outputs results in plain text.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-xml</db:code>  Outputs results as an XML document.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-lightxml</db:code>  Outputs results as a stream of XML tags.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-junitxml</db:code>  Outputs results as an JUnit XML document.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-csv</db:code>  Outputs results as comma-separated values (CSV). This mode is only suitable for benchmarks, since it suppresses normal pass/fail messages.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-teamcity</db:code>  Outputs results in TeamCity format.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-tap</db:code>  Outputs results in Test Anything Protocol (TAP) format.</db:para>
</db:listitem>
</db:itemizedlist>
<db:para>The first version of the <db:code>-o</db:code> option may be repeated in order to log test results in multiple formats, but no more than one instance of this option can log test results to standard output.</db:para>
<db:para>If the first version of the <db:code>-o</db:code> option is used, neither the second version of the <db:code>-o</db:code> option nor the <db:code>-txt</db:code>, <db:code>-xml</db:code>, <db:code>-lightxml</db:code>, <db:code>-teamcity</db:code>, <db:code>-junitxml</db:code> or <db:code>-tap</db:code> options should be used.</db:para>
<db:para>If neither version of the <db:code>-o</db:code> option is used, test results will be logged to standard output. If no format option is used, test results will be logged in plain text.</db:para>
</db:section>
<db:section xml:id="test-log-detail-options">
<db:title>Test Log Detail Options</db:title>
<db:para>The following command line options control how much detail is reported in test logs:</db:para>
<db:itemizedlist>
<db:listitem>
<db:para><db:code>-silent</db:code>  Silent output; only shows fatal errors, test failures and minimal status messages.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-v1</db:code>  Verbose output; shows when each test function is entered. (This option only affects plain text output.)</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-v2</db:code>  Extended verbose output; shows each <db:link xlink:href="qtest.xml#QCOMPARE">QCOMPARE</db:link>() and <db:link xlink:href="qtest.xml#QVERIFY">QVERIFY</db:link>(). (This option affects all output formats and implies <db:code>-v1</db:code> for plain text output.)</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-vs</db:code>  Shows all signals that get emitted and the slot invocations resulting from those signals. (This option affects all output formats.)</db:para>
</db:listitem>
</db:itemizedlist>
</db:section>
<db:section xml:id="testing-options">
<db:title>Testing Options</db:title>
<db:para>The following command-line options influence how tests are run:</db:para>
<db:itemizedlist>
<db:listitem>
<db:para><db:code>-functions</db:code>  Outputs all test functions available in the test, then quits.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-datatags</db:code>  Outputs all data tags available in the test. A global data tag is preceded by ' __global__ '.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-eventdelay</db:code> <db:emphasis>ms</db:emphasis>  If no delay is specified for keyboard or mouse simulation (<db:link xlink:href="qtest.xml#keyClick">QTest::keyClick</db:link>(), <db:link xlink:href="qtest.xml#mouseClick">QTest::mouseClick</db:link>() etc.), the value from this parameter (in milliseconds) is substituted.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-keydelay</db:code> <db:emphasis>ms</db:emphasis>  Like -eventdelay, but only influences keyboard simulation and not mouse simulation.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-mousedelay</db:code> <db:emphasis>ms</db:emphasis>  Like -eventdelay, but only influences mouse simulation and not keyboard simulation.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-maxwarnings</db:code> <db:emphasis>number</db:emphasis>  Sets the maximum number of warnings to output. 0 for unlimited, defaults to 2000.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-nocrashhandler</db:code>  Disables the crash handler on Unix platforms. On Windows, it re-enables the Windows Error Reporting dialog, which is turned off by default. This is useful for debugging crashes.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-platform</db:code> <db:emphasis>name</db:emphasis>  This command line argument applies to all Qt applications, but might be especially useful in the context of auto-testing. By using the &quot;offscreen&quot; platform plugin (-platform offscreen) it's possible to have tests that use QWidget or <db:link xlink:href="qwindow.xml">QWindow</db:link> run without showing anything on the screen. Currently the offscreen platform plugin is only fully supported on X11.</db:para>
</db:listitem>
</db:itemizedlist>
</db:section>
<db:section xml:id="benchmarking-options">
<db:title>Benchmarking Options</db:title>
<db:para>The following command line options control benchmark testing:</db:para>
<db:itemizedlist>
<db:listitem>
<db:para><db:code>-callgrind</db:code>  Uses Callgrind to time benchmarks (Linux only).</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-tickcounter</db:code>  Uses CPU tick counters to time benchmarks.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-eventcounter</db:code>  Counts events received during benchmarks.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-minimumvalue</db:code> <db:emphasis>n</db:emphasis>  Sets the minimum acceptable measurement value.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-minimumtotal</db:code> <db:emphasis>n</db:emphasis>  Sets the minimum acceptable total for repeated executions of a test function.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-iterations</db:code> <db:emphasis>n</db:emphasis>  Sets the number of accumulation iterations.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-median</db:code> <db:emphasis>n</db:emphasis>  Sets the number of median iterations.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>-vb</db:code>  Outputs verbose benchmarking information.</db:para>
</db:listitem>
</db:itemizedlist>
</db:section>
<db:section xml:id="miscellaneous-options">
<db:title>Miscellaneous Options</db:title>
<db:itemizedlist>
<db:listitem>
<db:para><db:code>-help</db:code>  Outputs the possible command line arguments and gives some useful help.</db:para>
</db:listitem>
</db:itemizedlist>
</db:section>
</db:section>
</db:section>
<db:section xml:id="qt-test-environment-variables">
<db:title>Qt Test Environment Variables</db:title>
<db:para>You can set certain environment variables in order to affect the execution of an autotest:</db:para>
<db:itemizedlist>
<db:listitem>
<db:para><db:code>QTEST_DISABLE_CORE_DUMP</db:code>  Setting this variable to a non-zero value will disable the generation of a core dump file.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>QTEST_DISABLE_STACK_DUMP</db:code>  Setting this variable to a non-zero value will prevent Qt Test from printing a stacktrace in case an autotest times out or crashes.</db:para>
</db:listitem>
<db:listitem>
<db:para><db:code>QTEST_FATAL_FAIL</db:code>  Setting this variable to a non-zero value will cause a failure in an autotest to immediately abort the entire autotest. This is useful to e.g. debug an unstable or intermittent failure in a test, by launching the test in a debugger. Support for this variable has been added in Qt 6.1.</db:para>
</db:listitem>
</db:itemizedlist>
</db:section>
<db:section xml:id="creating-a-benchmark">
<db:title>Creating a Benchmark</db:title>
<db:para>To create a benchmark, follow the instructions for creating a test and then add a <db:link xlink:href="qtest.xml#QBENCHMARK">QBENCHMARK</db:link> macro or <db:link xlink:href="qtest.xml#setBenchmarkResult">QTest::setBenchmarkResult</db:link>() to the test function that you want to benchmark. In the following code snippet, the macro is used:</db:para>
<db:programlisting language="cpp">class MyFirstBenchmark: public QObject
{
    Q_OBJECT
private slots:
    void myFirstBenchmark()
    {
        QString string1;
        QString string2;
        QBENCHMARK {
            string1.localeAwareCompare(string2);
        }
    }
};
</db:programlisting>
<db:para>A test function that measures performance should contain either a single <db:code>QBENCHMARK</db:code> macro or a single call to <db:code>setBenchmarkResult()</db:code>. Multiple occurrences make no sense, because only one performance result can be reported per test function, or per data tag in a data-driven setup.</db:para>
<db:para>Avoid changing the test code that forms (or influences) the body of a <db:code>QBENCHMARK</db:code> macro, or the test code that computes the value passed to <db:code>setBenchmarkResult()</db:code>. Differences in successive performance results should ideally be caused only by changes to the product you are testing. Changes to the test code can potentially result in misleading report of a change in performance. If you do need to change the test code, make that clear in the commit message.</db:para>
<db:para>In a performance test function, the <db:code>QBENCHMARK</db:code> or <db:code>setBenchmarkResult()</db:code> should be followed by a verification step using <db:link xlink:href="qtest.xml#QCOMPARE">QCOMPARE</db:link>(), <db:link xlink:href="qtest.xml#QVERIFY">QVERIFY</db:link>(), and so on. You can then flag a performance result as <db:emphasis>invalid</db:emphasis> if another code path than the intended one was measured. A performance analysis tool can use this information to filter out invalid results. For example, an unexpected error condition will typically cause the program to bail out prematurely from the normal program execution, and thus falsely show a dramatic performance increase.</db:para>
<db:section xml:id="selecting-the-measurement-back-end">
<db:title>Selecting the Measurement Back-end</db:title>
<db:para>The code inside the QBENCHMARK macro will be measured, and possibly also repeated several times in order to get an accurate measurement. This depends on the selected measurement back-end. Several back-ends are available. They can be selected on the command line:</db:para>
<db:anchor xml:id="testlib-benchmarking-measurement"/>
<db:informaltable style="generic">
<db:thead>
<db:tr>
<db:th>
<db:para>Name</db:para>
</db:th>
<db:th>
<db:para>Command-line Argument</db:para>
</db:th>
<db:th>
<db:para>Availability</db:para>
</db:th>
</db:tr>
</db:thead>
<db:tr valign="top">
<db:td>
<db:para>Walltime</db:para>
</db:td>
<db:td>
<db:para>(default)</db:para>
</db:td>
<db:td>
<db:para>All platforms</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para>CPU tick counter</db:para>
</db:td>
<db:td>
<db:para>-tickcounter</db:para>
</db:td>
<db:td>
<db:para>Windows, macOS, Linux, many UNIX-like systems.</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para>Event Counter</db:para>
</db:td>
<db:td>
<db:para>-eventcounter</db:para>
</db:td>
<db:td>
<db:para>All platforms</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para>Valgrind Callgrind</db:para>
</db:td>
<db:td>
<db:para>-callgrind</db:para>
</db:td>
<db:td>
<db:para>Linux (if installed)</db:para>
</db:td>
</db:tr>
<db:tr valign="top">
<db:td>
<db:para>Linux Perf</db:para>
</db:td>
<db:td>
<db:para>-perf</db:para>
</db:td>
<db:td>
<db:para>Linux</db:para>
</db:td>
</db:tr>
</db:informaltable>
<db:para>In short, walltime is always available but requires many repetitions to get a useful result. Tick counters are usually available and can provide results with fewer repetitions, but can be susceptible to CPU frequency scaling issues. Valgrind provides exact results, but does not take I/O waits into account, and is only available on a limited number of platforms. Event counting is available on all platforms and it provides the number of events that were received by the event loop before they are sent to their corresponding targets (this might include non-Qt events).</db:para>
<db:para>The Linux Performance Monitoring solution is available only on Linux and provides many different counters, which can be selected by passing an additional option <db:code>-perfcounter countername</db:code>, such as <db:code>-perfcounter cache-misses</db:code>, <db:code>-perfcounter branch-misses</db:code>, or <db:code>-perfcounter l1d-load-misses</db:code>. The default counter is <db:code>cpu-cycles</db:code>. The full list of counters can be obtained by running any benchmark executable with the option <db:code>-perfcounterlist</db:code>.</db:para>
<db:itemizedlist>
<db:listitem>
<db:para>Using the performance counter may require enabling access to non-privileged applications.</db:para>
</db:listitem>
<db:listitem>
<db:para>Devices that do not support high-resolution timers default to one-millisecond granularity.</db:para>
</db:listitem>
</db:itemizedlist>
<db:para>See <db:link xlink:href="qttestlib-tutorial5-example.xml">Writing a Benchmark</db:link> in the Qt Test Tutorial for more benchmarking examples.</db:para>
</db:section>
</db:section>
<db:section xml:id="using-global-test-data">
<db:title>Using Global Test Data</db:title>
<db:para>You can define <db:code>initTestCase_data()</db:code> to set up a global test data table. Each test is run once for each row in the global test data table. When the test function itself <db:link xlink:href="qttestlib-tutorial2-example.xml">is data-driven</db:link>, it is run for each local data row, for each global data row. So, if there are <db:code>g</db:code> rows in the global data table and <db:code>d</db:code> rows in the test's own data-table, the number of runs of this test is <db:code>g</db:code> times <db:code>d</db:code>.</db:para>
<db:para>Global data is fetched from the table using the <db:link xlink:href="qtest.xml#QFETCH_GLOBAL">QFETCH_GLOBAL</db:link>() macro.</db:para>
<db:para>The following are typical use cases for global test data:</db:para>
<db:itemizedlist>
<db:listitem>
<db:para>Selecting among the available database backends in <db:link xlink:href="qsql.xml">QSql</db:link> tests to run every test against every database.</db:para>
</db:listitem>
<db:listitem>
<db:para>Doing all networking tests with and without SSL (HTTP versus HTTPS) and proxying.</db:para>
</db:listitem>
<db:listitem>
<db:para>Testing a timer with a high precision clock and with a coarse one.</db:para>
</db:listitem>
<db:listitem>
<db:para>Selecting whether a parser shall read from a <db:link xlink:href="qbytearray.xml">QByteArray</db:link> or from a <db:link xlink:href="qiodevice.xml">QIODevice</db:link>.</db:para>
</db:listitem>
</db:itemizedlist>
<db:para>For example, to test each number provided by <db:code>roundTripInt_data()</db:code> with each locale provided by <db:code>initTestCase_data()</db:code>:</db:para>
<db:programlisting language="cpp">void TestQLocale::roundTripInt()
{
    QFETCH_GLOBAL(QLocale, locale);
    QFETCH(int, number);
    bool ok;
    QCOMPARE(locale.toInt(locale.toString(number), &amp;amp;ok), number);
    QVERIFY(ok);
}
</db:programlisting>
<db:para>On the command-line of a test you can pass the name of a function (with no test-class-name prefix) to run only that one function's tests. If the test class has global data, or the function is data-driven, you can append a data tag, after a colon, to run only that tag's data-set for the function. To specify both a global tag and a tag specific to the test function, combine them with a colon between, putting the global data tag first. For example</db:para>
<db:programlisting language="cpp">./testqlocale roundTripInt:zero
</db:programlisting>
<db:para>will run the <db:code>zero</db:code> test-case of the <db:code>roundTripInt()</db:code> test above (assuming its <db:code>TestQLocale</db:code> class has been compiled to an executable <db:code>testqlocale</db:code>) in each of the locales specified by <db:code>initTestCase_data()</db:code>, while</db:para>
<db:programlisting language="cpp">./testqlocale roundTripInt:C
</db:programlisting>
<db:para>will run all three test-cases of <db:code>roundTripInt()</db:code> only in the C locale and</db:para>
<db:programlisting language="cpp">./testqlocale roundTripInt:C:zero
</db:programlisting>
<db:para>will only run the <db:code>zero</db:code> test-case in the C locale.</db:para>
<db:para>Providing such fine-grained control over which tests are to be run can make it considerably easier to debug a problem, as you only need to step through the one test-case that has been seen to fail.</db:para>
</db:section>
</db:article>
