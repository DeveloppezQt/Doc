<?xml version="1.0" encoding="UTF-8"?>
<db:article xmlns:db="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.2" xml:lang="en_US">
<db:info>
<db:title>Contiguous Cache Example</db:title>
<db:productname>QtCore</db:productname>
<db:titleabbrev>Qt Core Reference Documentation</db:titleabbrev>
<db:abstract>
<db:para>The Contiguous Cache example shows how to use <db:link xlink:href="qcontiguouscache.xml">QContiguousCache</db:link> to manage memory usage for very large models. In some environments memory is limited and, even when it isn't, users still dislike an application using excessive memory. Using <db:link xlink:href="qcontiguouscache.xml">QContiguousCache</db:link> to manage a list, rather than loading the entire list into memory, allows the application to limit the amount of memory it uses, regardless of the size of the data set it accesses.</db:para>
</db:abstract>
<db:pubdate>2025-06-29</db:pubdate>
<db:date>2025-06-29</db:date>
<db:authorgroup>
<db:author>
<db:orgname class="corporation">The Qt Company Ltd.</db:orgname>
</db:author>
</db:authorgroup>
</db:info>
<db:para>The simplest way to use <db:link xlink:href="qcontiguouscache.xml">QContiguousCache</db:link> is to cache as items are requested. When a view requests an item at row N it is also likely to ask for items at rows near to N.</db:para>
<db:programlisting language="cpp">QVariant RandomListModel::data(const QModelIndex &amp;index, int role) const
{
    if (role != Qt::DisplayRole)
        return QVariant();

    int row = index.row();

    if (row &gt; m_rows.lastIndex()) {
        if (row - m_rows.lastIndex() &gt; lookAhead)
            cacheRows(row-halfLookAhead, qMin(m_count, row+halfLookAhead));
        else while (row &gt; m_rows.lastIndex())
            m_rows.append(fetchRow(m_rows.lastIndex()+1));
    } else if (row &lt; m_rows.firstIndex()) {
        if (m_rows.firstIndex() - row &gt; lookAhead)
            cacheRows(qMax(0, row-halfLookAhead), row+halfLookAhead);
        else while (row &lt; m_rows.firstIndex())
            m_rows.prepend(fetchRow(m_rows.firstIndex()-1));
    }

    return m_rows.at(row);
}

void RandomListModel::cacheRows(int from, int to) const
{
    for (int i = from; i &lt;= to; ++i)
        m_rows.insert(i, fetchRow(i));
}
</db:programlisting>
<db:para>After getting the row, the class determines if the row is in the bounds of the contiguous cache's current range. It would have been equally valid to simply have the following code instead.</db:para>
<db:programlisting language="cpp">while (row &gt; m_rows.lastIndex())
    m_rows.append(fetchWord(m_rows.lastIndex()+1);
while (row &lt; m_rows.firstIndex())
    m_rows.prepend(fetchWord(m_rows.firstIndex()-1);
</db:programlisting>
<db:para>However a list will often jump rows if the scroll bar is used directly, resulting in the code above causing every row between the old and new rows to be fetched.</db:para>
<db:para>Using QContiguousCache::lastIndex() and QContiguousCache::firstIndex() allows the example to determine what part of the list the cache is currently caching. These values don't represent the indexes into the cache's own memory, but rather a virtual infinite array that the cache represents.</db:para>
<db:para>By using QContiguousCache::append() and QContiguousCache::prepend() the code ensures that items that may be still on the screen are not lost when the requested row has not moved far from the current cache range. QContiguousCache::insert() can potentially remove more than one item from the cache as <db:link xlink:href="qcontiguouscache.xml">QContiguousCache</db:link> does not allow for gaps. If your cache needs to quickly jump back and forth between rows with significant gaps between them consider using <db:link xlink:href="qcache.xml">QCache</db:link> instead.</db:para>
<db:para>And thats it. A perfectly reasonable cache, using minimal memory for a very large list. In this case the accessor for getting the words into the cache generates random information rather than fixed information. This allows you to see how the cache range is kept for a local number of rows when running the example.</db:para>
<db:programlisting language="cpp">QString RandomListModel::fetchRow(int position) const
{
    return QString::number(rand() % ++position);
}
</db:programlisting>
<db:para>It is also worth considering pre-fetching items into the cache outside of the application's paint routine. This can be done either with a separate thread or using a <db:link xlink:href="qtimer.xml">QTimer</db:link> to incrementally expand the range of the cache prior to rows being requested out of the current cache range.</db:para>
<db:section>
<db:title>List of Files</db:title>
<db:para>Files:</db:para>
<db:section>
<db:title>List of Files</db:title>
<db:itemizedlist>
<db:listitem>
<db:para><db:link xlink:href="contiguouscache/contiguouscache.pro">contiguouscache/contiguouscache.pro</db:link></db:para></db:listitem>
<db:listitem>
<db:para><db:link xlink:href="contiguouscache/main.cpp">contiguouscache/main.cpp</db:link></db:para></db:listitem>
<db:listitem>
<db:para><db:link xlink:href="contiguouscache/randomlistmodel.cpp">contiguouscache/randomlistmodel.cpp</db:link></db:para></db:listitem>
<db:listitem>
<db:para><db:link xlink:href="contiguouscache/randomlistmodel.h">contiguouscache/randomlistmodel.h</db:link></db:para></db:listitem>
</db:itemizedlist>
</db:section>
</db:section></db:article>
